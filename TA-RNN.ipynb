{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e028bf42-2bc6-40ec-9037-dd9e6db60f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\henry\\miniconda3\\envs\\cv_proj1\\lib\\site-packages\\ucimlrepo\\fetch.py:97: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_url)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned shape: (101766, 49)\n",
      "Index(['race', 'gender', 'age', 'admission_type_id',\n",
      "       'discharge_disposition_id', 'admission_source_id', 'time_in_hospital',\n",
      "       'num_lab_procedures', 'num_procedures', 'num_medications',\n",
      "       'number_outpatient', 'number_emergency', 'number_inpatient', 'diag_1',\n",
      "       'diag_2', 'diag_3', 'number_diagnoses', 'max_glu_serum', 'A1Cresult',\n",
      "       'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
      "       'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
      "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
      "       'tolazamide', 'examide', 'citoglipton', 'insulin',\n",
      "       'glyburide-metformin', 'glipizide-metformin',\n",
      "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
      "       'metformin-pioglitazone', 'change', 'diabetesMed', 'readmitted',\n",
      "       'diag_1_group', 'diag_2_group', 'diag_3_group', 'readmit_30d'],\n",
      "      dtype='object')\n",
      "X_long shape: (101766, 1, 8)\n",
      "X_time shape: (101766, 1, 1)\n",
      "X_demo shape: (101766, 48)\n",
      "Positive rate: 0.112\n",
      "Model: \"ta_rnn_simplified\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " longitudinal (InputLayer)      [(None, 1, 8)]       0           []                               \n",
      "                                                                                                  \n",
      " time_gaps (InputLayer)         [(None, 1, 1)]       0           []                               \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 1, 9)         0           ['longitudinal[0][0]',           \n",
      "                                                                  'time_gaps[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 64)           18944       ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 64)           0           ['lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 32)           2080        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " demographics (InputLayer)      [(None, 48)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 80)           0           ['dense_4[0][0]',                \n",
      "                                                                  'demographics[0][0]']           \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            81          ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,105\n",
      "Trainable params: 21,105\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "255/255 [==============================] - 2s 3ms/step - loss: 0.3751 - accuracy: 0.8829 - auc: 0.5623 - val_loss: 0.3417 - val_accuracy: 0.8888 - val_auc: 0.6098\n",
      "Epoch 2/10\n",
      "255/255 [==============================] - 1s 2ms/step - loss: 0.3425 - accuracy: 0.8882 - auc: 0.6094 - val_loss: 0.3396 - val_accuracy: 0.8890 - val_auc: 0.6181\n",
      "Epoch 3/10\n",
      "255/255 [==============================] - 1s 2ms/step - loss: 0.3407 - accuracy: 0.8883 - auc: 0.6156 - val_loss: 0.3385 - val_accuracy: 0.8887 - val_auc: 0.6236\n",
      "Epoch 4/10\n",
      "255/255 [==============================] - 1s 3ms/step - loss: 0.3392 - accuracy: 0.8883 - auc: 0.6226 - val_loss: 0.3375 - val_accuracy: 0.8888 - val_auc: 0.6281\n",
      "Epoch 5/10\n",
      "255/255 [==============================] - 1s 2ms/step - loss: 0.3387 - accuracy: 0.8884 - auc: 0.6245 - val_loss: 0.3370 - val_accuracy: 0.8887 - val_auc: 0.6321\n",
      "Epoch 6/10\n",
      "255/255 [==============================] - 1s 2ms/step - loss: 0.3378 - accuracy: 0.8884 - auc: 0.6305 - val_loss: 0.3368 - val_accuracy: 0.8890 - val_auc: 0.6339\n",
      "Epoch 7/10\n",
      "255/255 [==============================] - 1s 2ms/step - loss: 0.3374 - accuracy: 0.8884 - auc: 0.6330 - val_loss: 0.3369 - val_accuracy: 0.8888 - val_auc: 0.6325\n",
      "Epoch 8/10\n",
      "255/255 [==============================] - 1s 2ms/step - loss: 0.3371 - accuracy: 0.8885 - auc: 0.6342 - val_loss: 0.3364 - val_accuracy: 0.8891 - val_auc: 0.6354\n",
      "Epoch 9/10\n",
      "255/255 [==============================] - 1s 2ms/step - loss: 0.3368 - accuracy: 0.8883 - auc: 0.6360 - val_loss: 0.3361 - val_accuracy: 0.8890 - val_auc: 0.6373\n",
      "Epoch 10/10\n",
      "255/255 [==============================] - 1s 2ms/step - loss: 0.3366 - accuracy: 0.8883 - auc: 0.6364 - val_loss: 0.3366 - val_accuracy: 0.8891 - val_auc: 0.6351\n",
      "637/637 [==============================] - 1s 694us/step\n",
      "\n",
      "TA-RNN-style model results:\n",
      "  accuracy: 0.888\n",
      "  roc_auc: 0.644\n",
      "  f1_pos: 0.022\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from diabetes_utils import clean_diabetes_data, plot_and_save_metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# 1. Load and clean data\n",
    "diabetes_data = fetch_ucirepo(id=296)\n",
    "X = diabetes_data.data.features\n",
    "y = diabetes_data.data.targets\n",
    "\n",
    "if \"readmitted\" not in y.columns:\n",
    "    y.columns = [\"readmitted\"]\n",
    "\n",
    "df = pd.concat([X, y], axis=1)\n",
    "df_clean = clean_diabetes_data(df)\n",
    "\n",
    "print(\"Cleaned shape:\", df_clean.shape)\n",
    "print(df_clean.columns)\n",
    "\n",
    "\n",
    "# 2. Build encounter-level \"sequences\" (T = 1)\n",
    "# numeric features used at each encounter\n",
    "long_feats = [\n",
    "    \"time_in_hospital\",\n",
    "    \"num_lab_procedures\",\n",
    "    \"num_procedures\",\n",
    "    \"num_medications\",\n",
    "    \"number_outpatient\",\n",
    "    \"number_emergency\",\n",
    "    \"number_inpatient\",\n",
    "    \"number_diagnoses\",\n",
    "]\n",
    "\n",
    "# demographic / categorical features\n",
    "demo_cols = [\n",
    "    \"race\",\n",
    "    \"gender\",\n",
    "    \"age\",\n",
    "    \"diag_1_group\",\n",
    "    \"diag_2_group\",\n",
    "    \"diag_3_group\",\n",
    "    \"insulin\",\n",
    "    \"change\",\n",
    "    \"diabetesMed\",\n",
    "]\n",
    "\n",
    "# target label\n",
    "y_seq = df_clean[\"readmit_30d\"].values\n",
    "n_samples = df_clean.shape[0]\n",
    "\n",
    "# longitudinal numeric features as a 3D tensor: (samples, timesteps, features)\n",
    "X_long = df_clean[long_feats].values      \n",
    "X_long = X_long.reshape(n_samples, 1, -1) \n",
    "\n",
    "# simple time-gap channel: 1 for each real step (no padding here)\n",
    "X_time = np.ones((n_samples, 1, 1))           # shape (n_samples, 1, 1)\n",
    "\n",
    "# demographics as one-hot encoded 2D matrix\n",
    "demo_df = df_clean[demo_cols].copy()\n",
    "demo_df = pd.get_dummies(demo_df, columns=demo_cols, drop_first=True)\n",
    "X_demo = demo_df.values                   \n",
    "\n",
    "print(\"X_long shape:\", X_long.shape)\n",
    "print(\"X_time shape:\", X_time.shape)\n",
    "print(\"X_demo shape:\", X_demo.shape)\n",
    "print(\"Positive rate:\", y_seq.mean().round(3))\n",
    "\n",
    "\n",
    "# 3. Trainâ€“test split and scaling\n",
    "X_train_long, X_test_long, \\\n",
    "X_train_time, X_test_time, \\\n",
    "X_train_demo, X_test_demo, \\\n",
    "y_train, y_test = train_test_split(\n",
    "    X_long,\n",
    "    X_time,\n",
    "    X_demo,\n",
    "    y_seq,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_seq,\n",
    ")\n",
    "\n",
    "# scale longitudinal numeric features across all time steps\n",
    "n_long_feats = X_train_long.shape[2]\n",
    "scaler_long = StandardScaler()\n",
    "\n",
    "# Convert to 2D for scaling: (samples * timesteps, features)\n",
    "X_train_long_2d = X_train_long.reshape(-1, n_long_feats)\n",
    "X_test_long_2d = X_test_long.reshape(-1, n_long_feats)\n",
    "\n",
    "# Fit scaler on train and transform train/test\n",
    "X_train_long_2d = scaler_long.fit_transform(X_train_long_2d)\n",
    "X_test_long_2d = scaler_long.transform(X_test_long_2d)\n",
    "\n",
    "# Convert back to 3D: (samples, timesteps, features)\n",
    "X_train_long = X_train_long_2d.reshape(X_train_long.shape)\n",
    "X_test_long = X_test_long_2d.reshape(X_test_long.shape)\n",
    "\n",
    "\n",
    "# 4. Define simplified TA-RNN-style model\n",
    "T = X_train_long.shape[1]            # should be 1\n",
    "n_demo_features = X_train_demo.shape[1]\n",
    "\n",
    "# inputs: sequence features, time gap channel, demographics\n",
    "long_input = Input(shape=(T, n_long_feats), name=\"longitudinal\")\n",
    "time_input = Input(shape=(T, 1), name=\"time_gaps\")\n",
    "demo_input = Input(shape=(n_demo_features,), name=\"demographics\")\n",
    "\n",
    "# attach time gaps to each time step\n",
    "seq_input = Concatenate(axis=-1)([long_input, time_input])\n",
    "\n",
    "# LSTM over the (length-1) sequence\n",
    "x = LSTM(64)(seq_input)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "\n",
    "# combine sequence representation with demographics\n",
    "x = Concatenate(axis=-1)([x, demo_input])\n",
    "\n",
    "output = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "ta_rnn_model = Model(\n",
    "    inputs=[long_input, time_input, demo_input],\n",
    "    outputs=output,\n",
    "    name=\"ta_rnn_simplified\",\n",
    ")\n",
    "\n",
    "ta_rnn_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")],\n",
    ")\n",
    "\n",
    "ta_rnn_model.summary()\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_auc\",\n",
    "    patience=2,\n",
    "    mode=\"max\",\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "\n",
    "# 5. Train model\n",
    "history = ta_rnn_model.fit(\n",
    "    [X_train_long, X_train_time, X_train_demo],\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "\n",
    "# 6. Evaluate and save plots\n",
    "y_prob = ta_rnn_model.predict([X_test_long, X_test_time, X_test_demo]).ravel()\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "ta_rnn_results = {\n",
    "    \"accuracy\": round(accuracy_score(y_test, y_pred), 3),\n",
    "    \"roc_auc\": round(roc_auc_score(y_test, y_prob), 3),\n",
    "    \"f1_pos\":  round(f1_score(y_test, y_pred, zero_division=0), 3),\n",
    "}\n",
    "\n",
    "print(\"\\nTA-RNN-style model results:\")\n",
    "for k, v in ta_rnn_results.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# Save plots\n",
    "plot_and_save_metrics(\"ta_rnn\", y_test, y_prob)\n",
    "\n",
    "# Save probabilites\n",
    "np.save(\"y_test_tarnn.npy\", y_test)\n",
    "np.save(\"prob_tarnn.npy\", y_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
